{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Dataset for Input to Model\n",
    "\n",
    "The dataset will be normalised and given as input to the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from Dataset_Preparation import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset from .npy\n",
    "Loads the dataset and splits into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDatasetFromFile():\n",
    "    X = np.load('NP-Dataset/X.npy')\n",
    "    y = np.load('NP-Dataset/y.npy')\n",
    "    #Train-Test Split. random_state equivalent to seed()\n",
    "#     X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=1)\n",
    "    indices = sss.split(X,y)\n",
    "    indices = list(indices)\n",
    "#     print (\"Indices: \",indices[0])\n",
    "    trainIndices,testIndices = indices[0][0],indices[0][1] \n",
    "    trainX = X[trainIndices]\n",
    "    trainY = y[trainIndices]\n",
    "    testX = X[testIndices]\n",
    "    testY = y[testIndices]\n",
    "    return trainX,testX,trainY,testY\n",
    "#     return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper funciton to One-Hot-Encode Labels\n",
    "[1,2,3] ==> [[1,0,0],[0,1,0],[0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneHotEncoded_y(y):\n",
    "    \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    encoded_y = encoder.transform(y)\n",
    "    encoded_y = encoded_y.reshape(-1,1)\n",
    "    categorical_y = np_utils.to_categorical(encoded_y)\n",
    "    \n",
    "    return categorical_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function To Stretch ,Normalize and OneHotEncode Data\n",
    "Data is stretched into 1X1024 vectors and normalized (range b/w 0 & 1) . Labels are OneHotEncoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizedDataset():\n",
    "    #Reshaping and \n",
    "    X_train,X_test,y_train,y_test = loadDatasetFromFile()\n",
    "    X_train = np.reshape(X_train,(-1,1024))\n",
    "    X_test = np.reshape(X_test,(-1,1024))\n",
    "    \n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    \n",
    "    y_train = oneHotEncoded_y(y_train)\n",
    "    y_test = oneHotEncoded_y(y_test)\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function To Decode the Label to Correct Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getProbableClass(x):\n",
    "    index = np.argmax(x)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function That Gives Dataset to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mal_char_data():\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = normalizedDataset()\n",
    "    \n",
    "    n_rows = 32\n",
    "    n_cols = 32\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0],n_rows,n_cols,1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],n_rows,n_cols,1)\n",
    "\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = mal_char_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25931, 32, 32, 1), (8644, 32, 32, 1), (25931, 133), (8644, 133))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.NumpyArrayIterator at 0x7f394b6470d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen.flow(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen.flow(X_train, batch_size=1,\n",
    "                          save_to_dir='NP-Dataset/', save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
